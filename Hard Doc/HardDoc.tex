\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{hyperref} 
\usepackage{amssymb}
\numberwithin{equation}{section}
\newenvironment{Proof}
	{\par\noindent{ДОКАЗАТЕЛЬСТВО.}}
	{\hfill$\scriptstyle$}
\begin{document}
	\begin{titlepage}
		\begin{center}
			\large
			МОСКОВСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ \\
			имени М.В. ЛОМОНОСОВА \\
			МЕХАНИКО-МАТЕМАТИЧЕСКИЙ ФАКУЛЬТЕТ\\ 
	
			\bf А. В. Чашкин \\
			\Large 
			ЛЕКЦИИ\\
			ПО ДИСКРЕТНОЙ МАТЕМАТИКЕ\\
			\normalsize
			Учебное пособие
			
			\vspace{\stretch{1}}
			Москва $\cdot$ 2007\pagebreak
		\end{center}
	\end{titlepage}   
	\newpage
	\tableofcontents
	\newpage
	\section{Линейные коды}
	Код $G$ называется линейным ($n$, $k$)-кодом, если он является $k$-мерным линейным подпространством пространства $\mathbb{B}^n$. Справедлива следующая теорема о кодовом расстоянии линейного кода. 
	
	\newtheorem{Def}{Теорема}[section]
	
		\begin{Def}\label{oneone}
			В каждом линейном коде $G$ кодовое расстояние $d$ равно весу его минимального ненулевого элемента:
		\end{Def}
		\begin{center}
			$ d = \min_{{\bf g}\not=0,{\bf g}\in G} || {\bf g} || $.
		\end{center}
		
	\begin{Proof}
		Так как нулевой набор всегда принадлежит линейному коду, то, очевидно, что кодовое расстояние не
		превосходит веса минимального ненулевого элемента. Допустим, что $d < min ||{\bf g}||$. В этом
		случае в $G$ найдутся два элемента $\bf{g}_1$ и $\bf{g}_2$, расстояние между которыми меньше
		$d$. Следовательно,
		\begin{center}
			$ || {\bf g}_1 \oplus {\bf g}_2 || = d({\bf g}_1,{\bf g}_2) < d. $
		\end{center}
		С другой стороны, сумма ${\bf g}_1 \oplus {\bf g}_2$ обязательно приналежит $G$. Поэтому $||{\bf g }_1 \oplus {\bf g}_2 || \ge d$. Пришли к противоречию. Теорема доказана.
	\end{Proof}
	
	Теорема \ref{oneone} является частным случаем следующего более общего утверждения об ошибках, 
	исправляемых линейными кодами

	\begin{Def}\label{onetwo}
		В линейном коде множества исправляемых ошибок всех элементов совпадают.
	\end{Def}
	
	\begin{Proof}
		Допустим, что теорема не верна, и в каком-нибудь линейном коде $G$ найдутся такие два элемента
		${\bf g}_1$ и ${\bf g}_2$, что вектор c принадлежит множествуисправляемых ошибок элемента
		${\bf g}_1$ и не принадлежит
		множествуисправляемых ошибок элемента ${\bf g}_2$. Тогда для вектора ${\bf g}_1 \oplus {\bf c}$ 
		ближайшим элементом кода будет ${\bf g}_1$, а для вектора ${\bf g}_2 \oplus {\bf c}$  найдется
		элемент кода ${\bf g}_3$, расстояние до которого не меньше, чем до ${\bf g}_2$. Следовательно, 
		существует вектор ${\bf c}'$ такой, что ${\bf g}_2 \oplus {\bf c} \oplus {\bf c}' = {\bf g}_3$ и
		$||{\bf c}'|| \le ||{\bf c}||$. Но тогда вектор ${\bf c} \oplus {\bf c}' = {\bf g}_2 \oplus 
		{\bf g}_3 = {\bf g}_4$ является элементом кода $G$. Поэтому расстояние от вектора ${\bf g}_1 
		\oplus {\bf c} = {\bf g}_1 \oplus {\bf g}_4 \oplus {\bf c}$ до элемента ${\bf g}_1 \oplus 
		{\bf g}_4$ не меньше, чем расстояние до ${\bf g}_1$, т. е. вектор ${\bf c}$ не принадлежит 
		множествуисправляемых ошибок элемента ${\bf g}_1$. Полученное противоречие показывает, что 
		множества исправляемых ошибок всех элементов совпадают. Теорема \ доказана.
	\end{Proof}\newpage
	
	Теорема \ref{onetwo} позволяет говорить о множестве ошибок, исправляемых линейным кодом. Пусть 
	линейный код $G$ исправляет ошибки из множества $C$. Повторяя доказательство теоремы \ref{onetwo}, 
	нетрудно показать, что
	
	\begin{equation}\label{eqone}
		{\bf c}_i \oplus {\bf c}_j \not\in G \textrm{ для всех } {\bf c}_i, {\bf c}_j \textrm{ из } C.
	\end{equation}
	
	Действительно, если в $C$ найдутся такие ${\bf c}_i$ и ${\bf c}_j$, что ${\bf c}_i \oplus {\bf c}_j\in 
	G$, то для каждого из этих векторов найдется по крайней мере два ближайших элемента
	кода --- нулевой и ${\bf c}_i \oplus {\bf c}_j$.
	
	Булева ($k,n$)-матрица ${\bf G}$ называется \textit{порождающей} матрицей линейного кода$G$, если 
	линейная оболочка $\langle {\bf g}_1, \ldots ,{\bf g}_k \rangle$ строк матрицы ${\bf G}$ совпадает
	с $G$. При помощи порождающей матрицы ${\bf G}$ очень просто выполняется процедура кодирования: для 
	преобразования информационного вектора ${\bf a}$ длины $k$ в кодовое слово ${\bf g}$ длины $n$ 
	достаточно вычислить произведение ${\bf aG}$.
	
	Булева ($n-k,n$)-матрица ${\bf H}$ называется \textit{проверочной} матрицей линейного кода $G$, если 
	${\bf Hg = 0}$ для каждого ${\bf g} \in G$ и ${\bf Hx \not=0}$ для каждого ${\bf x} \not\in G$. Вектор
	${\bf Hx}$ называется \textit{синдромом} вектора ${\bf x}$ и обозначается символом $S$. Нетрудно 
	видеть, что ${\bf Hc_i} \not= {\bf Hc_j}$ для любых исправляемых кодом $G$ ошибок ${\bf c_i}$ и ${\bf 
	c_j}$, так как в противном случае ${\bf H(c_i \oplus c_j)=0}$ и, следовательно, ${\bf c_i} \oplus {\bf 
	c_j} \in G$, что, очевидно, невозможно. Таким образом, справедлива следующая теорема. 
	
	\begin{Def}\label{onethree}
		Для того, чтобы матрица  ${\bf H}$ была проверочной матрицей кода, исправляющего ошибки из
		множества $C$, необходимо и достаточно, чтобы ${\bf Hc_i} \not= {\bf Hc_j}$ для любых ошибок 
		${\bf Hc_j}$ и ${\bf Hc_j}$ из $C$.
	\end{Def}
	Отметим, что 
	\begin{center}
		${\bf H(g \oplus c) = H(g) \oplus H(c) = H(c)}$
	\end{center}
	для любого элемента кода ${\bf g}$ и любого вектора ошибок ${\bf c}$. Поэтому вычисление 
	синдрома может существенно упростить декодирование по сравнению с общим нелинейным случаем. Для
	декодирования набора ${\bf x}$ надо вычислить его синдром и затем сравнить полученный результат с 
	заранее вычисленными синдромами векторов ошибок. Такое декодирование называется синдромным и его 
	сложность (без учета сложности вычисления синдрома) есть \textit{$n2^n-k$}. Эту величину можно 
	значительно уменьшить при помощи метода согласования, успешно работающего в различных ситуациях.
	Опишем этот метод. \newpage
	
	Пусть линейный ($n,k$)-код $G$ исправляет $t$ ошибок. Допустим, что при	передаче вектора
	${\bf g}$ произошло не более $t$ ошибок, и был получен вектор ${\bf x}$. Пусть ${\bf c}$ — вектор 
	ошибок, т. е. ${\bf g} \oplus {\bf c} = {\bf x}$. Пусть	$A$ — множество синдромов $S({\bf c}_l)$ всех 
	векторов ошибок ${\bf c}_l$, вес которых не превосходит $\lceil t/2 \rceil$, B --- множество попарных 
	сумм синдрома $S({\bf x})$ принятого вектора ${\bf x}$ и синдромов
	$S({\bf c}_m)$ всех векторов ошибок ${\bf c}_m$, вес которых не превосходит $\lfloor t/2 \rfloor$.
	Так как любой вектор, вес которого не превосходит $t$, можно представить в виде суммы двух векторов, 
	вес первого из которых не превосходит $\lceil t/2 \rceil$,
	а второго --- $\lfloor t/2 \rfloor$, то, очевидно, что найдутся такие векторы ${\bf c}_i$ и 
	${\bf c}_l$, что ${\bf c}={\bf c}_i \oplus {\bf c}_j$, где $||{\bf c}_i|| \le \lceil t/2 \rceil$ и 
	$||{\bf c}_j|| \le \lfloor t/2 \rfloor$. Поэтому в силу линейности синдрома
	\begin{center}
		$S({\bf x})=S({\bf c})=S({\bf c}_i \oplus {\bf c}_j)=S({\bf c}_i) \oplus S({\bf c}_j)$
	\end{center}
	Переписав последнее равенство в виде $S({\bf x})=S({\bf c}_i) \oplus S({\bf c}_j)$, заключаем, что	
	существует непустое пересечение множеств $A$ и $B$, и если в этих множествах найти пару одинаковых 
	элементов, то по этой паре можно будет восстановить вектор ошибок. Найти такую пару можно следующим 
	образом. Сначала вычислим все синдромы из множества $A$ и все суммы из множества $B$. Затем упорядочим 
	множество $A$. После этого последовательно для каждого элемента из $B$ попробуем найти равный ему 
	элемент из	$A$. Если такой элемент есть, то его можно найти, выполнив не более $\lceil log_2|A|\rceil$
	сравнений текущего элемента из $B$ с элементами из $A$. Сначала элемент из $B$ сравнивается со средним 
	элементом из $A$. Если элемент из $B$ окажется меньше, то далее поиск ведется в первой половине
	$A$, если больше --- во второй половине	$A$. Если в	$A$ есть элемент, равный текущему элементу из
	$B$, то он будет обнаружен во время одного из сравнений. Нетрудно видеть, что для декодирования вектора
	${\bf x}$ достаточно выполнить
	\begin{equation}\label{eqtwo}
		\mathcal{O}(|B| log_2 |A|)=\mathcal{O}\left(\left(\sum_{i=0}^{\lfloor t/2 \rfloor}
		\begin{pmatrix}
			n \\ i
		\end{pmatrix}
		\right)log_2 \sum_{i=0}^{\lceil t/2 \rceil}
		\begin{pmatrix}
			n \\ i
		\end{pmatrix}
		\right)=\mathcal{O}\left(2^{nH(t/2n)}nH(t/2n)\right) 
	\end{equation}
	операции над векторами длины $n-k$.
	
	В следующей теореме устанавливается фундаментальное свойство линейных кодов, лежащее в основе 
	подавляющего числа конструкций этих	кодов.
	
	\begin{Def}\label{onefour}
		Для того, чтобы матрица ${\bf H}$ была проверочной матрицей линейного кода с кодовым расстоянием 
		не меньшим $d$ необходимо и достаточно, чтобы любые $d-1$ столбцов матрицы ${\bf H}$ были линейно 
		независимы.
	\end{Def}
	
	\begin{Proof}
		Установим необходимость. Пусть ${\bf H}$ --- проверочная матрица кода $G$ с расстоянием $d$. 
		Если в матрице ${\bf H}$ сумма столбцов с номерами $i_1,\ldots,i_l$ равна нулевому вектору, то 
		произведение ${\bf Hv}$ матрицы	${\bf H}$ и	вектора ${\bf v}$, у которого единичные компоненты 
		имеют номера $i_1,\ldots,i_l$, также будет равно нулевому вектору. Следовательно, вектор
		${\bf v}$ принадлежит $G$, и, поэтому, $l \ge d$. С другой стороны, если любые $d-1$ столбцов 
		матрицы ${\bf H}$ линейно независимы, то и произведение матрицы ${\bf H}$ и любого вектора
		${\bf v}$ с не более чем $d-1$ единичными компонентами не равно нулевому вектору, и в силу теоремы 
		\ref{oneone} нулевое пространство матрицы ${\bf H}$ будет кодом с расстоянием не меньшим
		$d$. Теорема доказана.
	\end{Proof}
	
	Докажем нижнюю оценкудля мощности максимальных линейных кодов, исправляющих данное число ошибок.
	Эта оценка называется неравенством Варшамова–Гилберта.
	
	\begin{Def}\label{onefive}
		Если числа $n$, $m$ и $d$ удовлетворяют неравенству 
		\begin{center}
			$2^{n-m}>\sum_{i=0}^d-2
			\begin{pmatrix}
				n-1 \\ i
			\end{pmatrix}$,
		\end{center}
		то существует линейный $(n,m)$-код с расстоянием $d$.
	\end{Def}
	
	\begin{Proof}
		Допустим, что найдется матрица ${\bf H}_k$ из $n-m$ строк и $k$ столбцов, у которых любые $d-1$ 
		столбцов линейно независимы. Тогда существует не более $\sum_{i=0}^{d-2}
		\begin{pmatrix}
			k \\ i
		\end{pmatrix}$
		различных линейных комбинации столбцов этой матрицы, в каждую из которых входит не более чем
		$d-2$ ненулевых слагаемых. Если $2^{n-m}>\sum_{i=0}^d-2
		\begin{pmatrix}
			k \\ i
		\end{pmatrix}$,
		то найдется хотя бы один ненулевой вектор ${\bf h}$ длины $n-m$, не совпадающий ни с одной из этих
		линейных комбинации. Нетрудно видеть, что в матрице ${\bf H}_k+1 = ({\bf H}_k{\bf h})$, 
		составленной из столбцов матрицы ${\bf H}_k$ и вектора ${\bf k}$, любые $d-1$ столбцов линейно 
		независимы, и в силу теоремы \ref{onefour} эта матрица будет проверочной матрицей кода с 
		расстоянием $d$. Теорема доказана.
	\end{Proof}
	
	Так как синдромы всех исправляемых линейными $(n,m)$-кодом ошибок различны, то неравенство 
	$n-m \ge \lceil log_2 \sum_{i=0}^t 
	\begin{pmatrix}
		n \\ i
	\end{pmatrix} \rceil$ 
	справедливо для любого такого кода, исправляющего $t$ ошибок. Объединив это неравенство с границей 
	Варшамова–Гилберта, для мощности максимального линейного $(n, m)$-кода
	$G$, исправляющего $t$ ошибок, получим двойное неравенство
	\begin{equation}\label{eqthree}
		\frac{2^n}{\sum_{i=0}^{2t-1}
		\begin{pmatrix}
			n \\ i
		\end{pmatrix}}
		\le |G| = 2^m \le 2^{n-\lceil log_2\sum_{i=0}^{t}
		\begin{pmatrix}
			n \\ i
		\end{pmatrix}\rceil}\le \frac{2^n}{\sum_{i=0}^{t}
		\begin{pmatrix}
			n \\ i
		\end{pmatrix}}
	\end{equation}
	являющееся аналогом неравенства (13.7) для произвольных кодов. Заметим, что нижняя оценка в 
	\ref{eqthree} немного усиливает нижнюю оценку в (13.7). Однако это усиление не столь велико, чтобы 
	существенно	улучшить оценки скорости линейных кодов по сравнению с аналогичными оценками (13.8) и 
	(13.9). Как и в случае произвольных кодов нетрудно показать, что для скорости максимального линейного 
	кода длины $n$, исправляющего $t$ ошибок, справедливы неравенства
	\begin{equation}\label{eqfour}
		1-H\left(\frac{2t}{n}\right)\le R\le 1-H\left(\frac{t}{n}\right)+\mathcal{O}\left(\frac{log_2 
		n}{n}\right)
	\end{equation}
	и что при помощи линейных кодов по двоичному симметричному каналу с вероятностью ошибки $p$ можно 
	передавать информацию с близкой к нулю вероятностью неправильного декодирования и скоростью
	\begin{equation}
	1-H((1+\delta)2p)\le R\le 1-H((1+\delta)p)
	\end{equation}
	где $\delta$ --- сколь угодно малое положительное число, удовлетворяющее неравенству  
	$1-H((1+\delta)2p)\le 1/2$
\end{document}